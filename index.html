<!DOCTYPE html>
<html>
    <head>
    <title>Antonio Emanuele Cinà | Website</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://fonts.googleapis.com/css?family=Noto+Sans" rel="stylesheet">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="./assets/css/resume.css">
    <link rel="icon" href="https://img.icons8.com/color/48/motarboard.png" type="image/png" />
  </head>

  <body>
      <div class="container">
      <header>
        <div id="name-wrapper">
          <div id="fullname">
            Antonio Emanuele Cinà
          </div>
          <div id="jobtitle">
            Tenure-Track Researcher (RTDA), University of Genoa
          </div>
          <div class="image-container">
            <img src="profile.jpg" alt="Profile Picture" class="responsive"> 
         </div>
        </div>
        <div id="contact">
          <div class="contact-item">
            <i class="fa fa-envelope" aria-hidden="true"></i> antonio.cina@unige.it
          </div>
          <div class="contact-item">
            <a href="https://rubrica.unige.it/personale/UkJOXVpo">
            <i class="fa fa-globe" aria-hidden="true"></i> Academic Page
            </a>
          </div>
          <div class="contact-item">
            <a href="https://github.com/Cinofix/">
            <i class="fa fa-github" aria-hidden="true"></i> GitHub
            </a>
          </div>
          <div class="citation-container">
            <cite>
              "A teacher affects eternity; he can never tell where his influence stops."
              <span class="citation-author">— Henry Adams</span>
            </cite>
            <cite>
              "The pursuit of truth and beauty is a sphere of activity in which we are permitted to remain children all our lives."
              <span class="citation-author">— Albert Einstein</span>
            </cite>
          </div>  
        </div>
      </header>
      <section id="biosketch">
        <div class="section-content">
          <h1>Biosketch</h1>
          <p><strong>Antonio Emanuele Cinà</strong>, born in October 1995, is a Tenure-Track Researcher (RTDA) at the University of Genoa, Italy, and a member of the <a href="https://www.saiferlab.ai/people/antonioemanuelecina">SAIfer Lab</a>. At the University of Genoa, Antonio contributes to the SAIfer Lab by actively conducting research and officially supervising PhD students. He is involved in teaching activities and delivers courses in both undergraduate and graduate programs, in Italian and English. He also supervises several Bachelor’s and Master’s theses.</p>
      
          <p>Previously, Antonio worked as a Post-Doc Researcher at the <a href="https://cispa.de/en">CISPA Helmholtz Center for Information Security</a>, a leading research institute located in Saarbrücken, Germany. There, he focused on cutting-edge research in cybersecurity and machine learning security. Antonio obtained his Ph.D. with honors in January 2023 from Ca' Foscari University of Venice, where he also completed his Bachelor’s and Master’s degrees in Computer Science, both with full marks and honors. At Ca' Foscari, Antonio received several personal awards for academic excellence, including being recognized as the third-best Computer Science student in 2016 and the best graduate of Ca' Foscari in 2017. He also served as an elected representative of the Ph.D. program in Computer Science at Ca' Foscari University from 2019 to 2021 and was recognized as an outstanding alumnus.</p>
      
          <p>Antonio is a member of the <em>IEEE Computer Society</em> and the <em>ACM Computer Society</em>.</p>
      
          <h3>Research Interests</h3>
          <p>Antonio Emanuele Cinà’s research is focused on two main fronts:</p>
          <ol>
            <li><strong>Machine Learning Security and Reliability:</strong> Antonio started his research in this field with his Master's thesis, focusing on the security and reliability of machine learning and deep learning models. He investigates vulnerabilities and errors that arise from spurious or adversarial correlations learned by the model during training, which can lead to unexpected behaviors such as misclassification or the generation of toxic content. His work has contributed to categorizing these risks, developing robustness benchmarks, and creating guidelines for designing resilient models.</li>
            <li><strong>Cybersecurity and AI for Scam Detection:</strong> During his Post-Doc at CISPA, Antonio expanded his research to include natural language processing and data clustering techniques for identifying cybercriminals and analyzing the methods they use to manipulate victims. This research aims to understand the strategies of cybercriminals and develop AI-based systems to help users identify and avoid these threats.</li>
          </ol>
      
          <h3>Research Objective</h3>
          <p>The core objective of Antonio’s research is to open the "black box" of learning models to ensure their correct, robust, reliable, and ethical use in both academic and industrial contexts. This involves thoroughly understanding systems, identifying vulnerabilities, interpreting the mechanisms causing failures, and addressing them to create more secure and transparent AI systems.</p>
        </div>
      </section>

      <section id="research-interests">
        <div class="section-content">
          <h1>Research Interests</h1>
        
          <div class="highlight">
            Machine Learning Security, Adversarial ML, Cybersecurity, NLP for Cybercrime, AI Robustness
          </div>
        </div>
      </section>

      <section id="education">
        <div class="section-content">
          <h1>Education and Academic Experience</h1>
          <div class="block">
            <div class="block-title">University of Genoa</div>
            <div class="block-subtitle">2023 - Present | Tenure-Track Researcher</div>
          </div>
          <div class="block">
            <div class="block-title">CISPA Helmholtz Center for Information Security</div>
            <div class="block-subtitle">2023 | Postdoctoral Researcher</div>
          </div>
          <div class="block">
            <div class="block-title">Ph.D. in Computer Science, Ca' Foscari University of Venice</div>
            <div class="block-subtitle">2019 - 2023</div>
          </div>
          <div class="block">
            <div class="block-title">M.Sc. in Computer Science, Ca' Foscari University of Venice</div>
            <div class="block-subtitle">2017 - 2019 | Summa cum laude</div>
          </div>
          <div class="block">
            <div class="block-title">B.Sc. in Computer Science, Ca' Foscari University of Venice</div>
            <div class="block-subtitle">2014 - 2017 | Summa cum laude, Best Graduate</div>
          </div>
        </div>
      </section>

      <section id="publications">
        <div class="section-content">
          <h1>Publications</h1>

          <h3>Journal Articles</h3>
          <ul>
            <li><b>Energy-Latency Attacks via Sponge Poisoning.</b> Information Sciences, 2025.</li>
            <li><b>Machine Learning Security against Data Poisoning: Are We There Yet?</b> IEEE Computer, 2024.</li>
            <li><b>Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence Functions.</b> International Journal of Machine Learning and Cybernetics, 2024.</li>
            <li><b>Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning.</b> ACM Computing Surveys, 2023.</li>
            <li><b>Hardening RGB-D Object Recognition Systems against Adversarial Patch Attacks.</b> Information Sciences, 2023.</li>
            <li><b>A Black-box Adversarial Attack for Poisoning Clustering.</b> Pattern Recognition, 2022.</li>
          </ul>
      
          <h3>Conference Papers</h3>
          <ul>
            <li><b>σ-zero: Gradient-based Optimization of ℓ0-norm Adversarial Examples.</b> International Conference on Learning Representations (ICLR), 2025.</li>
            <li><b>Pirates of Charity: Exploring Donation-based Abuses in Social Media Platforms.</b> The Web Conference (WWW), 2025.</li>
            <li><b>AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples.</b> AAAI Conference on Artificial Intelligence (AAAI), 2025.</li>
            <li><b>Understanding XAI Through the Philosopher’s Glasses: A Historical Perspective.</b> European Conference on Artificial Intelligence (ECAI), 2024.</li>
            <li><b>The Imitation Game: Exploring Brand Impersonation Attacks on Social Media Platforms.</b> USENIX Security Symposium, 2024.</li>
            <li><b>Conning the Crypto Conman: End-to-End Analysis of Cryptocurrency-based Technical Support Scams.</b> IEEE Symposium on Security and Privacy (SP), 2024.</li>
            <li><b>Minimizing Energy Consumption of Deep Learning Models by Energy-Aware Training.</b> International Conference on Image Analysis and Processing (ICIAP), 2023.</li>
            <li><b>Stealing with Uncertainty Quantification Models.</b> European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2023).</li>
            <li><b>The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison Linear Classifiers?</b> International Joint Conference on Neural Networks (IJCNN), 2021.</li>
          </ul>
        </div>
      </section>

      <section id="presentations">
        <div class="section-content">
          <h1>Participation as Speaker at International Conferences and Workshops</h1>
          <ul>
            <li><strong>2025</strong> – <b>σ-zero: Gradient-based Optimization of ℓ0-norm Adversarial Examples</b> @ ICLR</li>
            <li><strong>2025</strong> – <b>AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples</b> @ AAAI</li>
            <li><strong>2023</strong> – <b>On the Limitations of Model Stealing with Uncertainty Quantification Models</b> @ ICML Workshop: New Frontiers in Adversarial Machine Learning</li>
            <li><strong>2022</strong> – <b>Mislead Machine Learning</b> @ ITASEC Workshop: AI for Security and Security of AI</li>
            <li><strong>2021</strong> – <b>Explaining Backdoor Poisoning</b> @ ICCV Workshop: Adversarial Robustness in the Real World</li>
            <li><strong>2021</strong> – <b>Is Bilevel Optimization Really Needed to Poison Linear Classifiers?</b> @ IJCNN</li>
          </ul>
        </div>
      </section>
      
      <section id="invited-talks">
        <div class="section-content">
          <h1 class="section-title">Participation as Invited Speaker at International Conferences and Workshops</h1>
          <ul>
            <li><strong>2024</strong> – <b>Foundations of LLMs, Applications, and Security Risks</b> – Keynote, ICMLC</li>
            <li><strong>2024</strong> – <b>Reliable Machine Learning Security Benchmarking</b> – ML Security Workshop @ ICMLC</li>
            <li><strong>2024</strong> – <b>Robust ML: Benchmarking Best Practices</b> – ML for Cybersecurity Workshop @ ECML PKDD</li>
            <li><strong>2023</strong> – <b>Training with Malicious Teachers</b> – Robustness in Deep Learning Workshop @ GAMM</li>
            <li><strong>2022</strong> – <b>Where ML Security Is Broken: Poisoning Attacks</b> – Security of ML @ Dagstuhl Seminar</li>
            <li><strong>2022</strong> – <b>Mislead Machine Learning</b> – ASSG: AppSec and Cybersecurity Governance</li>
          </ul>
        </div>
      </section>
      <section id="other-activities">
        <div class="section-content">
          <h1>Other Activities as Speaker</h1>

          <h3>2024</h3>
          <ul>
            <li><b>Foundations of LLMs, Applications, and Security Risks</b> – PRALAB, University of Cagliari</li>
            <li><b>Data & MLOps in Sustainable Transportation & Logistics</b> – University of Pisa, Spoke 10 PNRR</li>
            <li><b>Training with Malicious Teachers: Poisoning Attacks</b> – PRALAB, University of Cagliari</li>
            <li><b>Handling Scientific Experiments with HPC Clusters & Slurm</b> – PRALAB, University of Cagliari</li>
          </ul>
          
          <h3>2023</h3>
          <ul>
            <li><b>Training with Malicious Teachers</b> – SoSySec Seminar, INRIA</li>
            <li><b>Dose Makes the Poison</b> – SAILab, Siena</li>
            <li><b>Dose Makes the Poison</b> – SmartLab, Prof. Fabio Roli</li>
          </ul>
          
          <h3>2022</h3>
          <ul>
            <li><b>AI in the Film Industry</b> – AIA, Villorba</li>
            <li><b>Mislead Machine Learning</b> – Codemotion Online Seminar</li>
          </ul>
        </div>
      </section>
  </body>
</html>
